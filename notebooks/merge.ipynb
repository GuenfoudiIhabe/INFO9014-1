{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery_path = \"../data/raw/Bakery_sales.csv\"\n",
    "coffee_shop_path = \"../data/raw/Coffee_Shop_Sales.csv\"\n",
    "bakery_sales = pd.read_csv(bakery_path)\n",
    "Coffee_sales = pd.read_csv(coffee_shop_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Coffee sales with EUR prices:\n",
      "                product_detail  unit_price  unit_price_eur\n",
      "0                  Ethiopia Rg         3.0            2.79\n",
      "1     Spicy Eye Opener Chai Lg         3.1            2.88\n",
      "2            Dark chocolate Lg         4.5            4.19\n",
      "3  Our Old Time Diner Blend Sm         2.0            1.86\n",
      "4     Spicy Eye Opener Chai Lg         3.1            2.88\n",
      "Saved cleaned file to: ../data/cleaned/Coffee_Shop_Sales_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Use a specific stable version of pandas\n",
    "%pip install pandas==2.0.3 -q\n",
    "\n",
    "import os\n",
    "USD_TO_EUR_RATE = 0.93\n",
    "\n",
    "# Convert USD to EUR and round to 2 decimal places\n",
    "Coffee_sales['unit_price_eur'] = (Coffee_sales['unit_price'] * USD_TO_EUR_RATE).round(2)\n",
    "\n",
    "# Display the first few rows to verify the conversion\n",
    "print(\"Coffee sales with EUR prices:\")\n",
    "print(Coffee_sales[['product_detail', 'unit_price', 'unit_price_eur']].head())\n",
    "\n",
    "# Save the cleaned CSV into the data cleaned folder.\n",
    "os.makedirs(\"../data/cleaned\", exist_ok=True)  # Create directory if it doesn't exist\n",
    "cleaned_csv_path = \"../data/cleaned/Coffee_Shop_Sales_cleaned.csv\"\n",
    "Coffee_sales.to_csv(cleaned_csv_path, index=False)\n",
    "print(f\"Saved cleaned file to: {cleaned_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned bakery sales file to: ../data/cleaned/Bakery_sales_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#clean the unit_price column by removing the € sign and converting the column to float\n",
    "bakery_sales[\"unit_price\"] = (\n",
    "    bakery_sales[\"unit_price\"]\n",
    "    .str.replace(\"€\", \"\", regex=False)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .str.replace(\" \", \"\", regex=False)\n",
    "    .str.replace('\"', \"\", regex=False)\n",
    "    .str.strip()\n",
    "    .astype(float)\n",
    ")\n",
    "#rename the columns to match the target schema\n",
    "bakery_sales = bakery_sales.rename(\n",
    "    columns={\n",
    "        \"ticket_number\": \"transaction_id\",\n",
    "        \"date\": \"transaction_date\",\n",
    "        \"time\": \"transaction_time\",\n",
    "        \"Quantity\": \"transaction_qty\",\n",
    "        \"article\": \"product_detail\",\n",
    "    }\n",
    ")\n",
    "#add the missing columns\n",
    "bakery_sales[\"store_id\"] = None\n",
    "bakery_sales[\"store_location\"] = None\n",
    "bakery_sales[\"product_id\"] = None\n",
    "bakery_sales[\"product_category\"] = \"Bakery\"\n",
    "bakery_sales[\"product_type\"] = None\n",
    "#reorder the columns\n",
    "bakery_sales = bakery_sales[\n",
    "    [\n",
    "        \"transaction_id\",\n",
    "        \"transaction_date\",\n",
    "        \"transaction_time\",\n",
    "        \"transaction_qty\",\n",
    "        \"store_id\",\n",
    "        \"store_location\",\n",
    "        \"product_id\",\n",
    "        \"unit_price\",\n",
    "        \"product_category\",\n",
    "        \"product_type\",\n",
    "        \"product_detail\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Save the cleaned bakery sales data to the cleaned folder\n",
    "bakery_cleaned_csv_path = \"../data/cleaned/Bakery_sales_cleaned.csv\"\n",
    "bakery_sales.to_csv(bakery_cleaned_csv_path, index=False)\n",
    "print(f\"Saved cleaned bakery sales file to: {bakery_cleaned_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coffee' 'Tea' 'Drinking Chocolate' 'Bakery' 'Flavours' 'Loose Tea'\n",
      " 'Coffee beans' 'Packaged Chocolate' 'Branded']\n"
     ]
    }
   ],
   "source": [
    "unique_categories = Coffee_sales['product_category'].unique()\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_type       3\n",
      "product_detail    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "bakery_items = Coffee_sales[Coffee_sales['product_category'] == 'Bakery'][['product_type', 'product_detail']].drop_duplicates()\n",
    "print(bakery_items.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAGUETTE' 'PAIN AU CHOCOLAT' 'PAIN' 'TRADITIONAL BAGUETTE' 'CROISSANT'\n",
      " 'BANETTE' 'BANETTINE' 'SPECIAL BREAD' 'COUPE' 'SAND JB EMMENTAL'\n",
      " 'KOUIGN AMANN' 'BOULE 200G' 'BOULE 400G' 'GAL FRANGIPANE 6P' 'CAMPAGNE'\n",
      " 'MOISSON' 'CAFE OU EAU' 'BRIOCHE' 'CEREAL BAGUETTE' 'SEIGLE' 'COMPLET'\n",
      " 'DIVERS PATISSERIE' 'GAL FRANGIPANE 4P' 'COOKIE' 'FICELLE'\n",
      " 'PAIN AUX RAISINS' 'GAL POMME 6P' 'GAL POMME 4P' 'FINANCIER X5'\n",
      " 'VIK BREAD' 'DIVERS VIENNOISERIE' 'GACHE' 'SANDWICH COMPLET'\n",
      " 'PAIN BANETTE' 'GRAND FAR BRETON' 'QUIM BREAD' 'SPECIAL BREAD KG'\n",
      " 'GD KOUIGN AMANN' 'BOULE POLKA' 'DEMI BAGUETTE' 'CHAUSSON AUX POMMES'\n",
      " 'BAGUETTE GRAINE' 'DIVERS CONFISERIE' 'SUCETTE' 'DIVERS BOULANGERIE'\n",
      " 'BOISSON 33CL' 'PATES' 'FORMULE SANDWICH' 'DIVERS SANDWICHS'\n",
      " 'CROISSANT AMANDES' 'PAIN CHOCO AMANDES' 'SACHET VIENNOISERIE' 'NANTAIS'\n",
      " 'CHOCOLAT' 'PAIN S/SEL' 'FONDANT CHOCOLAT' 'GAL POIRE CHOCO 6P'\n",
      " 'GAL POIRE CHOCO 4P' 'GALETTE 8 PERS' 'SAND JB' 'SACHET DE CROUTON'\n",
      " 'GRANDE SUCETTE' 'DEMI PAIN' 'TARTELETTE' 'FLAN' 'PARIS BREST' 'SAVARIN'\n",
      " 'FLAN ABRICOT' 'BAGUETTE APERO' 'MILLES FEUILLES' 'CHOU CHANTILLY'\n",
      " 'ECLAIR' 'ROYAL 4P' 'TARTE FRUITS 6P' 'TARTE FRUITS 4P' 'NOIX JAPONAISE'\n",
      " 'THE' 'BRIOCHETTE' 'ROYAL 6P' 'ECLAIR FRAISE PISTACHE' '.'\n",
      " 'GD FAR BRETON' 'TRIANGLES' 'TROPEZIENNE' 'TROPEZIENNE FRAMBOISE' 'ROYAL'\n",
      " 'TARTE FRAISE 6P' 'TARTELETTE FRAISE' 'TARTE FRAISE 4PER' 'FRAISIER'\n",
      " 'NID DE POULE' 'TARTELETTE CHOC' 'PAIN DE MIE' 'CRUMBLE' 'FINANCIER'\n",
      " 'DIVERS BOISSONS' 'CAKE' 'VIENNOISE' 'TRAITEUR' 'PAIN GRAINES'\n",
      " 'PLATPREPARE6,50' 'PLATPREPARE5,50' 'PLATPREPARE7,00'\n",
      " 'FORMULE PLAT PREPARE' 'ST HONORE' 'BROWNIES' 'RELIGIEUSE'\n",
      " 'PLATPREPARE6,00' 'DELICETROPICAL' 'CRUMBLECARAMEL OU PISTAE'\n",
      " 'PT NANTAIS' 'GD NANTAIS' 'DOUCEUR D HIVER' 'TROIS CHOCOLAT'\n",
      " 'ARTICLE 295' 'TARTE FINE' 'ENTREMETS' 'BRIOCHE DE NOEL' 'FRAMBOISIER'\n",
      " 'BUCHE 4PERS' 'BUCHE 6PERS' 'GD PLATEAU SALE' 'BUCHE 8PERS'\n",
      " 'PT PLATEAU SALE' 'REDUCTION SUCREES 12' 'PAIN NOIR'\n",
      " 'REDUCTION SUCREES 24' 'BOTTEREAU' 'MERINGUE' 'PALMIER' 'PAILLE'\n",
      " 'PLAT 6.50E' 'PLAT 7.60E' 'PLAT 7.00' 'PLAT' 'PLAT 8.30E' 'FORMULE PATE'\n",
      " 'GUERANDAIS' 'PALET BRETON' 'CARAMEL NOIX' 'MACARON' '12 MACARON'\n",
      " 'ARMORICAIN' 'PLAQUE TARTE 25P' 'SABLE F  P' 'PAIN SUISSE PEPITO'\n",
      " 'TULIPE' 'TARTELETTE COCKTAIL' 'SACHET DE VIENNOISERIE']\n"
     ]
    }
   ],
   "source": [
    "bakery_sales_new = pd.read_csv(\"bakery_sales_new.csv\")\n",
    "bakery_items_new = bakery_sales_new[bakery_sales_new['product_category'] == 'Bakery'][['product_detail']].drop_duplicates()\n",
    "print(bakery_items_new['product_detail'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bakery data from: ../data/cleaned/Bakery_sales_cleaned.csv\n",
      "         product_detail  product_type\n",
      "0              BAGUETTE         Bread\n",
      "1      PAIN AU CHOCOLAT         Bread\n",
      "2      PAIN AU CHOCOLAT         Bread\n",
      "3                  PAIN         Bread\n",
      "4  TRADITIONAL BAGUETTE         Bread\n",
      "5              BAGUETTE         Bread\n",
      "6             CROISSANT  Viennoiserie\n",
      "7               BANETTE         Bread\n",
      "8  TRADITIONAL BAGUETTE         Bread\n",
      "9             CROISSANT  Viennoiserie\n",
      "\n",
      "Product Type Distribution:\n",
      "product_type\n",
      "Bread            158909\n",
      "Service           20470\n",
      "Viennoiserie      20074\n",
      "Pastry            14965\n",
      "Sandwich           5951\n",
      "Other              3720\n",
      "Beverage           3390\n",
      "Cookie             3247\n",
      "Prepared Food      1804\n",
      "Confectionery      1466\n",
      "Assortment            9\n",
      "Name: count, dtype: int64\n",
      "Updated bakery data saved to: ../data/cleaned/Bakery_sales_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Coffee Shop and Bakery Data Integration\n",
    "\n",
    "This notebook processes and merges data from two sources: a Coffee Shop sales dataset and a Bakery sales dataset. The goal is to create a unified database schema that can store both datasets seamlessly, despite their different original structures.\n",
    "\n",
    "def map_bakery_product_types(df):\n",
    "    \"\"\"Map bakery product details to appropriate product types\"\"\"\n",
    "    \n",
    "    # Define category mappings - expanded with more comprehensive terms\n",
    "    bread_types = ['BAGUETTE', 'PAIN', 'BANETTE', 'BOULE', 'COMPLET', 'CAMPAGNE', \n",
    "                  'SEIGLE', 'MOISSON', 'CEREAL', 'POLKA', 'FICELLE', 'TRADITION', \n",
    "                  'SPECIAL BREAD', 'VIK BREAD', 'QUIM BREAD', 'PAIN BANETTE', 'NOIR',\n",
    "                  'BOULANGERIE', 'MIE', 'CEREAL BAGUETTE', 'GRAINE', 'PAIN S/SEL']\n",
    "    \n",
    "    viennoiserie_types = ['PAIN AU CHOCOLAT', 'CROISSANT', 'KOUIGN AMANN', 'PAIN AUX RAISINS', \n",
    "                         'BRIOCHE', 'CHAUSSON', 'VIENNOISERIE', 'BRIOCHETTE', 'PAIN SUISSE',\n",
    "                         'PALMIER', 'PAILLE', 'TULIPE']\n",
    "    \n",
    "    pastry_types = ['GAL', 'GALETTE', 'TARTE', 'FRANGIPANE', 'POMME', 'FAR BRETON', \n",
    "                   'TARTELETTE', 'KOUIGN', 'PATISSERIE', 'FLAN', 'PARIS BREST', 'SAVARIN',\n",
    "                   'MILLES FEUILLES', 'CHOU', 'ECLAIR', 'ROYAL', 'TROPEZIENNE', 'FRAISIER',\n",
    "                   'NID DE POULE', 'CRUMBLE', 'FINANCIER', 'CAKE', 'ST HONORE', 'BROWNIES',\n",
    "                   'RELIGIEUSE', 'DELICE', 'ENTREMETS', 'BUCHE']\n",
    "    \n",
    "    sandwich_types = ['SAND', 'SANDWICH', 'FORMULE SANDWICH']\n",
    "    \n",
    "    cookie_types = ['COOKIE', 'SABLE', 'PALET BRETON', 'NANTAIS', 'MERINGUE']\n",
    "    \n",
    "    beverage_types = ['CAFE', 'EAU', 'THE', 'BOISSON', 'CHOCOLAT']\n",
    "    \n",
    "    confectionery_types = ['CONFISERIE', 'SUCETTE', 'MACARON', 'CARAMEL']\n",
    "    \n",
    "    # Create a function to determine product type\n",
    "    def get_product_type(product_detail):\n",
    "        if pd.isna(product_detail):\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        product = str(product_detail).upper()\n",
    "        \n",
    "        if any(bread in product for bread in bread_types):\n",
    "            return \"Bread\"\n",
    "        elif any(item in product for item in viennoiserie_types):\n",
    "            return \"Viennoiserie\"\n",
    "        elif any(pastry in product for pastry in pastry_types):\n",
    "            return \"Pastry\"\n",
    "        elif any(sandwich in product for sandwich in sandwich_types):\n",
    "            return \"Sandwich\"\n",
    "        elif any(cookie in product for cookie in cookie_types):\n",
    "            return \"Cookie\"\n",
    "        elif any(beverage in product for beverage in beverage_types):\n",
    "            return \"Beverage\"\n",
    "        elif any(confectionery in product for confectionery in confectionery_types):\n",
    "            return \"Confectionery\"\n",
    "        elif \"COUPE\" in product:\n",
    "            return \"Service\"\n",
    "        elif \"PLATPREPARE\" in product or \"PLAT\" in product or \"TRAITEUR\" in product:\n",
    "            return \"Prepared Food\"\n",
    "        elif \"REDUCTION\" in product or \"PLATEAU\" in product:\n",
    "            return \"Assortment\"\n",
    "        else:\n",
    "            return \"Other\"\n",
    "    \n",
    "    # Apply the function to create product_type column\n",
    "    df['product_type'] = df['product_detail'].apply(get_product_type)\n",
    "    \n",
    "    return df\n",
    "\n",
    "cleaned_bakery_path = bakery_cleaned_csv_path  \n",
    "\n",
    "print(f\"Loading bakery data from: {cleaned_bakery_path}\")\n",
    "bakery_sales_cleaned = pd.read_csv(cleaned_bakery_path)\n",
    "\n",
    "bakery_sales_cleaned = map_bakery_product_types(bakery_sales_cleaned)\n",
    "\n",
    "print(bakery_sales_cleaned[['product_detail', 'product_type']].head(10))\n",
    "\n",
    "print(\"\\nProduct Type Distribution:\")\n",
    "print(bakery_sales_cleaned['product_type'].value_counts())\n",
    "\n",
    "bakery_sales_cleaned.to_csv(cleaned_bakery_path, index=False)\n",
    "print(f\"Updated bakery data saved to: {cleaned_bakery_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Mapping:\n",
      "BAGUETTE: 101\n",
      "PAIN AU CHOCOLAT: 102\n",
      "PAIN: 103\n",
      "TRADITIONAL BAGUETTE: 104\n",
      "CROISSANT: 105\n",
      "BANETTE: 106\n",
      "BANETTINE: 107\n",
      "SPECIAL BREAD: 108\n",
      "COUPE: 109\n",
      "SAND JB EMMENTAL: 110\n",
      "KOUIGN AMANN: 111\n",
      "BOULE 200G: 112\n",
      "BOULE 400G: 113\n",
      "GAL FRANGIPANE 6P: 114\n",
      "CAMPAGNE: 115\n",
      "MOISSON: 116\n",
      "CAFE OU EAU: 117\n",
      "BRIOCHE: 118\n",
      "CEREAL BAGUETTE: 119\n",
      "SEIGLE: 120\n",
      "COMPLET: 121\n",
      "DIVERS PATISSERIE: 122\n",
      "GAL FRANGIPANE 4P: 123\n",
      "COOKIE: 124\n",
      "FICELLE: 125\n",
      "PAIN AUX RAISINS: 126\n",
      "GAL POMME 6P: 127\n",
      "GAL POMME 4P: 128\n",
      "FINANCIER X5: 129\n",
      "VIK BREAD: 130\n",
      "DIVERS VIENNOISERIE: 131\n",
      "GACHE: 132\n",
      "SANDWICH COMPLET: 133\n",
      "PAIN BANETTE: 134\n",
      "GRAND FAR BRETON: 135\n",
      "QUIM BREAD: 136\n",
      "SPECIAL BREAD KG: 137\n",
      "GD KOUIGN AMANN: 138\n",
      "BOULE POLKA: 139\n",
      "DEMI BAGUETTE: 140\n",
      "CHAUSSON AUX POMMES: 141\n",
      "BAGUETTE GRAINE: 142\n",
      "DIVERS CONFISERIE: 143\n",
      "SUCETTE: 144\n",
      "DIVERS BOULANGERIE: 145\n",
      "BOISSON 33CL: 146\n",
      "PATES: 147\n",
      "FORMULE SANDWICH: 148\n",
      "DIVERS SANDWICHS: 149\n",
      "CROISSANT AMANDES: 150\n",
      "PAIN CHOCO AMANDES: 151\n",
      "SACHET VIENNOISERIE: 152\n",
      "NANTAIS: 153\n",
      "CHOCOLAT: 154\n",
      "PAIN S/SEL: 155\n",
      "FONDANT CHOCOLAT: 156\n",
      "GAL POIRE CHOCO 6P: 157\n",
      "GAL POIRE CHOCO 4P: 158\n",
      "GALETTE 8 PERS: 159\n",
      "SAND JB: 160\n",
      "SACHET DE CROUTON: 161\n",
      "GRANDE SUCETTE: 162\n",
      "DEMI PAIN: 163\n",
      "TARTELETTE: 164\n",
      "FLAN: 165\n",
      "PARIS BREST: 166\n",
      "SAVARIN: 167\n",
      "FLAN ABRICOT: 168\n",
      "BAGUETTE APERO: 169\n",
      "MILLES FEUILLES: 170\n",
      "CHOU CHANTILLY: 171\n",
      "ECLAIR: 172\n",
      "ROYAL 4P: 173\n",
      "TARTE FRUITS 6P: 174\n",
      "TARTE FRUITS 4P: 175\n",
      "NOIX JAPONAISE: 176\n",
      "THE: 177\n",
      "BRIOCHETTE: 178\n",
      "ROYAL 6P: 179\n",
      "ECLAIR FRAISE PISTACHE: 180\n",
      ".: 181\n",
      "GD FAR BRETON: 182\n",
      "TRIANGLES: 183\n",
      "TROPEZIENNE: 184\n",
      "TROPEZIENNE FRAMBOISE: 185\n",
      "ROYAL: 186\n",
      "TARTE FRAISE 6P: 187\n",
      "TARTELETTE FRAISE: 188\n",
      "TARTE FRAISE 4PER: 189\n",
      "FRAISIER: 190\n",
      "NID DE POULE: 191\n",
      "TARTELETTE CHOC: 192\n",
      "PAIN DE MIE: 193\n",
      "CRUMBLE: 194\n",
      "FINANCIER: 195\n",
      "DIVERS BOISSONS: 196\n",
      "CAKE: 197\n",
      "VIENNOISE: 198\n",
      "TRAITEUR: 199\n",
      "PAIN GRAINES: 200\n",
      "PLATPREPARE6,50: 201\n",
      "PLATPREPARE5,50: 202\n",
      "PLATPREPARE7,00: 203\n",
      "FORMULE PLAT PREPARE: 204\n",
      "ST HONORE: 205\n",
      "BROWNIES: 206\n",
      "RELIGIEUSE: 207\n",
      "PLATPREPARE6,00: 208\n",
      "DELICETROPICAL: 209\n",
      "CRUMBLECARAMEL OU PISTAE: 210\n",
      "PT NANTAIS: 211\n",
      "GD NANTAIS: 212\n",
      "DOUCEUR D HIVER: 213\n",
      "TROIS CHOCOLAT: 214\n",
      "ARTICLE 295: 215\n",
      "TARTE FINE: 216\n",
      "ENTREMETS: 217\n",
      "BRIOCHE DE NOEL: 218\n",
      "FRAMBOISIER: 219\n",
      "BUCHE 4PERS: 220\n",
      "BUCHE 6PERS: 221\n",
      "GD PLATEAU SALE: 222\n",
      "BUCHE 8PERS: 223\n",
      "PT PLATEAU SALE: 224\n",
      "REDUCTION SUCREES 12: 225\n",
      "PAIN NOIR: 226\n",
      "REDUCTION SUCREES 24: 227\n",
      "BOTTEREAU: 228\n",
      "MERINGUE: 229\n",
      "PALMIER: 230\n",
      "PAILLE: 231\n",
      "PLAT 6.50E: 232\n",
      "PLAT 7.60E: 233\n",
      "PLAT 7.00: 234\n",
      "PLAT: 235\n",
      "PLAT 8.30E: 236\n",
      "FORMULE PATE: 237\n",
      "GUERANDAIS: 238\n",
      "PALET BRETON: 239\n",
      "CARAMEL NOIX: 240\n",
      "MACARON: 241\n",
      "12 MACARON: 242\n",
      "ARMORICAIN: 243\n",
      "PLAQUE TARTE 25P: 244\n",
      "SABLE F  P: 245\n",
      "PAIN SUISSE PEPITO: 246\n",
      "TULIPE: 247\n",
      "TARTELETTE COCKTAIL: 248\n",
      "SACHET DE VIENNOISERIE: 249\n",
      "\n",
      "Missing values before cleaning:\n",
      "transaction_id           0\n",
      "transaction_date         0\n",
      "transaction_time         0\n",
      "transaction_qty          0\n",
      "store_id            234005\n",
      "store_location      234005\n",
      "product_id          234005\n",
      "unit_price               0\n",
      "product_category         0\n",
      "product_type             0\n",
      "product_detail           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "transaction_id           0\n",
      "transaction_date         0\n",
      "transaction_time         0\n",
      "transaction_qty          0\n",
      "store_id            234005\n",
      "store_location      234005\n",
      "product_id               0\n",
      "unit_price               0\n",
      "product_category         0\n",
      "product_type             0\n",
      "product_detail           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create a mapping of product names to product IDs.\n",
    "raw_product_names = [\n",
    "    'BAGUETTE', 'PAIN AU CHOCOLAT', 'PAIN', 'TRADITIONAL BAGUETTE', 'CROISSANT',\n",
    "    'BANETTE', 'BANETTINE', 'SPECIAL BREAD', 'COUPE', 'SAND JB EMMENTAL',\n",
    "    'KOUIGN AMANN', 'BOULE 200G', 'BOULE 400G', 'GAL FRANGIPANE 6P', 'CAMPAGNE',\n",
    "    'MOISSON', 'CAFE OU EAU', 'BRIOCHE', 'CEREAL BAGUETTE', 'SEIGLE', 'COMPLET',\n",
    "    'DIVERS PATISSERIE', 'GAL FRANGIPANE 4P', 'COOKIE', 'FICELLE',\n",
    "    'PAIN AUX RAISINS', 'GAL POMME 6P', 'GAL POMME 4P', 'FINANCIER X5',\n",
    "    'VIK BREAD', 'DIVERS VIENNOISERIE', 'GACHE', 'SANDWICH COMPLET',\n",
    "    'PAIN BANETTE', 'GRAND FAR BRETON', 'QUIM BREAD', 'SPECIAL BREAD KG',\n",
    "    'GD KOUIGN AMANN', 'BOULE POLKA', 'DEMI BAGUETTE', 'CHAUSSON AUX POMMES',\n",
    "    'BAGUETTE GRAINE', 'DIVERS CONFISERIE', 'SUCETTE', 'DIVERS BOULANGERIE',\n",
    "    'BOISSON 33CL', 'PATES', 'FORMULE SANDWICH', 'DIVERS SANDWICHS',\n",
    "    'CROISSANT AMANDES', 'PAIN CHOCO AMANDES', 'SACHET VIENNOISERIE', 'NANTAIS',\n",
    "    'CHOCOLAT', 'PAIN S/SEL', 'FONDANT CHOCOLAT', 'GAL POIRE CHOCO 6P',\n",
    "    'GAL POIRE CHOCO 4P', 'GALETTE 8 PERS', 'SAND JB', 'SACHET DE CROUTON',\n",
    "    'GRANDE SUCETTE', 'DEMI PAIN', 'TARTELETTE', 'FLAN', 'PARIS BREST', 'SAVARIN',\n",
    "    'FLAN ABRICOT', 'BAGUETTE APERO', 'MILLES FEUILLES', 'CHOU CHANTILLY',\n",
    "    'ECLAIR', 'ROYAL 4P', 'TARTE FRUITS 6P', 'TARTE FRUITS 4P', 'NOIX JAPONAISE',\n",
    "    'THE', 'BRIOCHETTE', 'ROYAL 6P', 'ECLAIR FRAISE PISTACHE', '.',\n",
    "    'GD FAR BRETON', 'TRIANGLES', 'TROPEZIENNE', 'TROPEZIENNE FRAMBOISE', 'ROYAL',\n",
    "    'TARTE FRAISE 6P', 'TARTELETTE FRAISE', 'TARTE FRAISE 4PER', 'FRAISIER',\n",
    "    'NID DE POULE', 'TARTELETTE CHOC', 'PAIN DE MIE', 'CRUMBLE', 'FINANCIER',\n",
    "    'DIVERS BOISSONS', 'CAKE', 'VIENNOISE', 'TRAITEUR', 'PAIN GRAINES',\n",
    "    'PLATPREPARE6,50', 'PLATPREPARE5,50', 'PLATPREPARE7,00',\n",
    "    'FORMULE PLAT PREPARE', 'ST HONORE', 'BROWNIES', 'RELIGIEUSE',\n",
    "    'PLATPREPARE6,00', 'DELICETROPICAL', 'CRUMBLECARAMEL OU PISTAE',\n",
    "    'PT NANTAIS', 'GD NANTAIS', 'DOUCEUR D HIVER', 'TROIS CHOCOLAT',\n",
    "    'ARTICLE 295', 'TARTE FINE', 'ENTREMETS', 'BRIOCHE DE NOEL', 'FRAMBOISIER',\n",
    "    'BUCHE 4PERS', 'BUCHE 6PERS', 'GD PLATEAU SALE', 'BUCHE 8PERS',\n",
    "    'PT PLATEAU SALE', 'REDUCTION SUCREES 12', 'PAIN NOIR',\n",
    "    'REDUCTION SUCREES 24', 'BOTTEREAU', 'MERINGUE', 'PALMIER', 'PAILLE',\n",
    "    'PLAT 6.50E', 'PLAT 7.60E', 'PLAT 7.00', 'PLAT', 'PLAT 8.30E', 'FORMULE PATE',\n",
    "    'GUERANDAIS', 'PALET BRETON', 'CARAMEL NOIX', 'MACARON', '12 MACARON',\n",
    "    'ARMORICAIN', 'PLAQUE TARTE 25P', 'SABLE F  P', 'PAIN SUISSE PEPITO',\n",
    "    'TULIPE', 'TARTELETTE COCKTAIL', 'SACHET DE VIENNOISERIE'\n",
    "]\n",
    "\n",
    "# Clean names: upper case and remove spaces.\n",
    "clean_product_names = [name.strip().upper() for name in raw_product_names]\n",
    "\n",
    "# Create a dictionary where each product name is mapped to a unique id.\n",
    "product_map = {name: idx for idx, name in enumerate(clean_product_names, start=101)}\n",
    "\n",
    "# Show the mapping information.\n",
    "print(\"Product Mapping:\")\n",
    "for product, pid in product_map.items():\n",
    "    print(f\"{product}: {pid}\")\n",
    "\n",
    "# Read the cleaned sales file using the path variable that already exists\n",
    "df = pd.read_csv(bakery_cleaned_csv_path)\n",
    "\n",
    "# Check missing values before fixing data.\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean product details and format the string.\n",
    "df['product_detail'] = df['product_detail'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Ensure product_id exists and fill missing ones with 0.\n",
    "if 'product_id' not in df.columns:\n",
    "    df['product_id'] = 0\n",
    "else:\n",
    "    df['product_id'] = df['product_id'].fillna(0)\n",
    "\n",
    "# Map the product details to product IDs using the dictionary.\n",
    "df['product_id'] = df.apply(\n",
    "    lambda row: product_map.get(row['product_detail'], 999) if row['product_id'] == 0 else row['product_id'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert transaction ids to integer type.\n",
    "df['transaction_id'] = df['transaction_id'].astype(int)\n",
    "\n",
    "# Show missing values after cleaning.\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>transaction_qty</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_location</th>\n",
       "      <th>product_id</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150040</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>08:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>101</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bread</td>\n",
       "      <td>BAGUETTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150040</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>08:38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>102</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bread</td>\n",
       "      <td>PAIN AU CHOCOLAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150041</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>09:14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Lower Manhattan</td>\n",
       "      <td>102</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bread</td>\n",
       "      <td>PAIN AU CHOCOLAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150041</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>09:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Lower Manhattan</td>\n",
       "      <td>103</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bread</td>\n",
       "      <td>PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150042</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>09:25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>104</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>Bread</td>\n",
       "      <td>TRADITIONAL BAGUETTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id transaction_date transaction_time  transaction_qty  \\\n",
       "0          150040       2021-01-02            08:38              1.0   \n",
       "1          150040       2021-01-02            08:38              3.0   \n",
       "2          150041       2021-01-02            09:14              2.0   \n",
       "3          150041       2021-01-02            09:14              1.0   \n",
       "4          150042       2021-01-02            09:25              5.0   \n",
       "\n",
       "   store_id   store_location  product_id  unit_price product_category  \\\n",
       "0         3          Astoria         101        0.90           Bakery   \n",
       "1         3          Astoria         102        1.20           Bakery   \n",
       "2         5  Lower Manhattan         102        1.20           Bakery   \n",
       "3         5  Lower Manhattan         103        1.15           Bakery   \n",
       "4         3          Astoria         104        1.20           Bakery   \n",
       "\n",
       "  product_type        product_detail  \n",
       "0        Bread              BAGUETTE  \n",
       "1        Bread      PAIN AU CHOCOLAT  \n",
       "2        Bread      PAIN AU CHOCOLAT  \n",
       "3        Bread                  PAIN  \n",
       "4        Bread  TRADITIONAL BAGUETTE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_stores = Coffee_sales[['store_id', 'store_location']].drop_duplicates()\n",
    "unique_tickets = bakery_sales['transaction_id'].unique()\n",
    "\n",
    "# Attribute a random store to each transaction\n",
    "np.random.seed(42)\n",
    "ticket_store_mapping = {ticket: np.random.choice(unique_stores['store_id']) for ticket in unique_tickets}\n",
    "\n",
    "df['store_id'] = bakery_sales['transaction_id'].map(ticket_store_mapping)\n",
    "df['store_location'] = df['store_id'].map(unique_stores.set_index('store_id')['store_location'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning complete. Cleaned data saved as '../data/cleaned/Bakery_sales_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "output_filename = bakery_cleaned_csv_path\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"\\nCleaning complete. Cleaned data saved as '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee sales IDs range: 1 to 149116\n",
      "Bakery sales IDs range: 149117 to 383121\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/Bakery_sales_cleaned.csv\")\n",
    "df2 = pd.read_csv(\"../data/cleaned/Coffee_Shop_Sales_cleaned.csv\")\n",
    "\n",
    "df2['sales_id'] = range(1, len(df2) + 1)\n",
    "\n",
    "# assign IDs to Bakery sales starting after Coffee Shop\n",
    "df['sales_id'] = range(len(df2) + 1, len(df2) + len(df) + 1)\n",
    "\n",
    "df.to_csv(\"../data/cleaned/Bakery_sales_cleaned.csv\", index=False)\n",
    "df2.to_csv(\"../data/cleaned/Coffee_Shop_Sales_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Coffee sales IDs range:\", df2['sales_id'].iloc[0], \"to\", df2['sales_id'].iloc[-1])\n",
    "print(\"Bakery sales IDs range:\", df['sales_id'].iloc[0], \"to\", df['sales_id'].iloc[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
